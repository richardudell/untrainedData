<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Untrained Data</title>
  <style>
    body {
      font-family: Georgia, serif;
      margin: 0;
      padding: 0 1rem;
      max-width: 700px;
      margin: auto;
      background-color: #fdfdfd;
      color: #111;
      line-height: 1.6;
    }

    header {
      padding: 2rem 0;
      text-align: center;
      border-bottom: 1px solid #ddd;
    }

    h1 {
      font-size: 2.2rem;
      margin: 0;
    }

    nav {
      margin-top: 0.5rem;
    }

    nav a {
      margin: 0 0.5rem;
      text-decoration: none;
      color: #444;
      font-size: 0.95rem;
    }

    nav a:hover {
      text-decoration: underline;
    }

    section {
      margin: 2rem 0;
    }

    article h2 {
      font-size: 1.5rem;
      margin-bottom: 0.25rem;
    }

    article p {
      margin: 0.5rem 0 1rem;
    }

    footer {
      text-align: center;
      padding: 2rem 0;
      font-size: 0.85rem;
      color: #777;
      border-top: 1px solid #eee;
    }

    a {
      color: #0077cc;
    }

    a:hover {
      color: #005999;
    }
  </style>
</head>
<body>

  <section id="essays">
    <article>
      <h2>I Don’t Want AI to Think for Me</h2>
      <p>Just like everyone else, I’m feeling the weight of LLMs. The existential questions. The skill decay. The unease that maybe we’re automating away something essential about being human. Since AI entered the mainstream, I’ve felt a growing responsibility to approach technology with more intention — to create with it more than I consume through it. To shape my relationship with these tools instead of letting them shape me.

        So when I saw Claude’s new "learning mode," I didn’t just see a feature. I saw a signal.
        
        Claude’s learning mode refuses to give direct answers. Instead, it prompts you to think. It asks questions. It behaves less like a magic box and more like a thoughtful teacher. That shift — from delivery to dialogue — feels both subtle and profound.
        
        And yes, let’s be clear: you could recreate this mode right now in any LLM with a prompt like:
        
        "You are an educator whose goal is to help me master [subject]. Do not give me direct answers. Use Socratic questioning. Prioritize long-term understanding over short-term correctness."
        
        In fact, people have already been doing this for a while.
        
        But what makes Claude’s version exciting is that it reflects a culture shift, not a technical one. It makes learning the default. It assumes users want growth, not just output. And it points toward a future where AI helps us think — not think for us.
        
        </p>
        <p>
        
        Where This Could Go
        
        I’ve said before that using LLMs can feel like having a refreshing drink — something quick, easy, and satisfying. But Claude’s learning mode reminded me that sometimes, what we really need isn’t refreshment. It’s friction. A bit of resistance that forces us to think instead of outsource.

        Now imagine students logging into school computers that only run this version of Claude. They can still access the full power of an LLM — but only through the lens of learning. No shortcuts. No essays written for you. Just a thoughtful, persistent tutor asking you to explain yourself.
        
        That’s not automation. That’s amplification.
        
        It’s a hopeful vision. But also, a complicated one. If every interaction with the internet gets funneled through an AI model, what do we lose? Maybe a lot. The open web, independent websites, weird blogs, digital rabbit holes — these things might fade. That would be a loss of culture.
        
        And yet, we’d gain something too: an interface that meets us where we are. One that tunes itself to our goals, our values, our context. Imagine switching modes for different parts of life: weekday-you gets a high-performance productivity AI. Weekend-you gets one that helps plan outdoor adventures or ask bigger questions.
        
        What happens when your phone doesn’t just serve up apps — but reflects who you’re becoming?
        
      </p>
      <p>What I’m Doing Next
        
        Over the next few weeks, I’m going to interview a handful of educators — teachers I know, people in my network — to get their take on all of this:
        
        Would they use something like Claude’s learning mode in the classroom?
        
        Do they see it as a helpful scaffold — or a threat?
        
        What’s exciting? What’s concerning?
        
        Could this push students to think more deeply — or just look like learning on the surface?
        
        This is the first post in what I hope will be a short series. I’ll share what I learn as I go — not to make grand claims, but to think out loud with people who think deeply about how we learn.
        
        Because the future of education might not come from a feature. It might come from a prompt.
        
        And the best thing we can ask AI? Might just be: ask me something better.</p>
    </article>


  <footer>
    &copy; 2025 Untrained Data. Built with coffee and curiosity.
  </footer>
</body>
</html>
